{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Title: \n",
    "Store Sales - Time Series Forecasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Business Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction\n",
    "This project focuses on time series forecasting to predict store sales for Corporation Favorita, a large Ecuadorian-based grocery retailer. The objective is to build a model that accurately predicts the unit sales for thousands of items sold at different Favorita stores.\n",
    "\n",
    "\n",
    "### 1.1. Objectives\n",
    "Understand the data: The first objective is to gain insights into the store sales data, including store-specific information, product families, promotions, and sales numbers. This understanding will enable the company to make informed business decisions.\n",
    "\n",
    "Predict store sales: Develop a reliable time series forecasting model that accurately predicts the unit sales for different product families at various Favorita stores. This will help the company optimize inventory management, plan promotions, and improve overall sales performance.\n",
    "\n",
    "### 1.2. Methodology\n",
    "To achieve the objectives, we will follow a structured approach:\n",
    "\n",
    "Data Exploration: Thoroughly explore the provided datasets to understand the available features, their distributions, and relationships. This step will provide initial insights into the store sales data and help identify any data quality issues.\n",
    "\n",
    "Data Preparation: Handle missing values, perform feature engineering, and encode categorical variables as necessary. This step may involve techniques like imputation, scaling, and one-hot encoding.\n",
    "\n",
    "Time Series Analysis: Analyze the temporal aspects of the data, including trends, seasonality, and potential outliers. This analysis will provide a deeper understanding of the underlying patterns in store sales over time.\n",
    "\n",
    "Model Selection and Training: Select appropriate time series forecasting models and train them using the prepared data. Consider incorporating external factors like promotions, holidays, and oil prices, if available, to enhance the forecasting accuracy.\n",
    "\n",
    "Model Evaluation: Evaluate the trained models using appropriate metrics, such as mean absolute error (MAE), root mean squared error (RMSE), or mean absolute percentage error (MAPE). Assess the models' performance and identify the most accurate and reliable forecasting model.\n",
    "\n",
    "Model Deployment and Forecasting: Deploy the chosen model to predict store sales for future time periods, leveraging the provided test dataset. Generate forecasts for the target period and assess the model's ability to capture the sales patterns accurately.\n",
    "\n",
    "By following this methodology, we aim to provide valuable insights to the telecom company and develop a reliable predictive model for customer churn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install pyodbc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Handling\n",
    "import pyodbc\n",
    "from dotenv import dotenv_values\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import seaborn as sns\n",
    "\n",
    "# Other Packages\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the data from SQL database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from the .env file into a dictionary\n",
    "environment_vars = dotenv_values('.env')\n",
    "\n",
    "# Get the credential values from the '.env' file \n",
    "server = environment_vars.get(\"SERVER\")\n",
    "database = environment_vars.get(\"DATABASE\")\n",
    "username = environment_vars.get(\"USERNAME\")\n",
    "password = environment_vars.get(\"PASSWORD\")\n",
    "\n",
    "# Create the connection string using the ODBC driver format\n",
    "conn_str = f'DRIVER={{ODBC Driver 17 for SQL Server}};SERVER={server};DATABASE={database};UID={username};PWD={password}'\n",
    "\n",
    "# Establish the connection using the connection string\n",
    "conn = pyodbc.connect(conn_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query the first table 'oil' in the database\n",
    "query1 = 'SELECT * FROM dbo.oil'\n",
    "oil_df = pd.read_sql(query1, conn)\n",
    "\n",
    "# Query the second table 'holidays_events' in the database\n",
    "query2 = 'SELECT * FROM dbo.holidays_events'\n",
    "holidays_events_df = pd.read_sql(query2, conn)\n",
    "\n",
    "# Query the third table 'stores' in the database\n",
    "query3 = 'SELECT * FROM dbo.stores'\n",
    "stores_df = pd.read_sql(query3, conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>dcoilwtico</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>93.139999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-03</td>\n",
       "      <td>92.970001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-04</td>\n",
       "      <td>93.120003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-07</td>\n",
       "      <td>93.199997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  dcoilwtico\n",
       "0  2013-01-01         NaN\n",
       "1  2013-01-02   93.139999\n",
       "2  2013-01-03   92.970001\n",
       "3  2013-01-04   93.120003\n",
       "4  2013-01-07   93.199997"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "oil_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>type</th>\n",
       "      <th>locale</th>\n",
       "      <th>locale_name</th>\n",
       "      <th>description</th>\n",
       "      <th>transferred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2012-03-02</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Manta</td>\n",
       "      <td>Fundacion de Manta</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2012-04-01</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Regional</td>\n",
       "      <td>Cotopaxi</td>\n",
       "      <td>Provincializacion de Cotopaxi</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2012-04-12</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Cuenca</td>\n",
       "      <td>Fundacion de Cuenca</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Libertad</td>\n",
       "      <td>Cantonizacion de Libertad</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2012-04-21</td>\n",
       "      <td>Holiday</td>\n",
       "      <td>Local</td>\n",
       "      <td>Riobamba</td>\n",
       "      <td>Cantonizacion de Riobamba</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date     type    locale locale_name                    description  \\\n",
       "0  2012-03-02  Holiday     Local       Manta             Fundacion de Manta   \n",
       "1  2012-04-01  Holiday  Regional    Cotopaxi  Provincializacion de Cotopaxi   \n",
       "2  2012-04-12  Holiday     Local      Cuenca            Fundacion de Cuenca   \n",
       "3  2012-04-14  Holiday     Local    Libertad      Cantonizacion de Libertad   \n",
       "4  2012-04-21  Holiday     Local    Riobamba      Cantonizacion de Riobamba   \n",
       "\n",
       "   transferred  \n",
       "0        False  \n",
       "1        False  \n",
       "2        False  \n",
       "3        False  \n",
       "4        False  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "holidays_events_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>type</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Quito</td>\n",
       "      <td>Pichincha</td>\n",
       "      <td>D</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Santo Domingo</td>\n",
       "      <td>Santo Domingo de los Tsachilas</td>\n",
       "      <td>D</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   store_nbr           city                           state type  cluster\n",
       "0          1          Quito                       Pichincha    D       13\n",
       "1          2          Quito                       Pichincha    D       13\n",
       "2          3          Quito                       Pichincha    D        8\n",
       "3          4          Quito                       Pichincha    D        9\n",
       "4          5  Santo Domingo  Santo Domingo de los Tsachilas    D        4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display the dataframe\n",
    "stores_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Train and Test Datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>sales</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id        date  store_nbr      family  sales  onpromotion\n",
       "0   0  2013-01-01          1  AUTOMOTIVE    0.0            0\n",
       "1   1  2013-01-01          1   BABY CARE    0.0            0\n",
       "2   2  2013-01-01          1      BEAUTY    0.0            0\n",
       "3   3  2013-01-01          1   BEVERAGES    0.0            0\n",
       "4   4  2013-01-01          1       BOOKS    0.0            0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.csv\")\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>family</th>\n",
       "      <th>onpromotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3000888</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>AUTOMOTIVE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3000889</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BABY CARE</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3000890</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEAUTY</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3000891</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BEVERAGES</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3000892</td>\n",
       "      <td>2017-08-16</td>\n",
       "      <td>1</td>\n",
       "      <td>BOOKS</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id        date  store_nbr      family  onpromotion\n",
       "0  3000888  2017-08-16          1  AUTOMOTIVE            0\n",
       "1  3000889  2017-08-16          1   BABY CARE            0\n",
       "2  3000890  2017-08-16          1      BEAUTY            2\n",
       "3  3000891  2017-08-16          1   BEVERAGES           20\n",
       "4  3000892  2017-08-16          1       BOOKS            0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = pd.read_csv(\"test.csv\")\n",
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Transactions Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>store_nbr</th>\n",
       "      <th>transactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>25</td>\n",
       "      <td>770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>2111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>2</td>\n",
       "      <td>2358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>3</td>\n",
       "      <td>3487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013-01-02</td>\n",
       "      <td>4</td>\n",
       "      <td>1922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  store_nbr  transactions\n",
       "0  2013-01-01         25           770\n",
       "1  2013-01-02          1          2111\n",
       "2  2013-01-02          2          2358\n",
       "3  2013-01-02          3          3487\n",
       "4  2013-01-02          4          1922"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transactions_df = pd.read_csv(\"transactions.csv\")\n",
    "transactions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions and Hypothesis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis\n",
    "Null Hypothesis (H0): Promotional activities have no significant impact on store sales.\n",
    "Alternative Hypothesis (H1): Promotional activities have a significant impact on store sales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions\n",
    "1. Is the train dataset complete, including all the required dates?\n",
    "2. Which dates have the lowest and highest sales for each year?\n",
    "3. Did the earthquake have an impact on sales?\n",
    "4. Are certain groups of stores selling more products? (Cluster, city, state, type)\n",
    "5. Are sales affected by promotions, oil prices, and holidays?\n",
    "6. What analysis can be derived from the date and its extractable features?\n",
    "7. What is the difference between RMSLE, RMSE, MSE (or why is the MAE greater than all of them?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis: EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Understanding the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An in-depth exploration of the datasets is presented to gain insights into the available variables,their distributions and relationships. This step will provide an initial undertanding of the datasets to identify any data quality issues that will inform the cleaning and pre-processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Shape of The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Dataset: (3000888, 6)\n",
      "Test Datasets: (28512, 5)\n"
     ]
    }
   ],
   "source": [
    "# Print out the shapes of the train and test datasets\n",
    "print(f\"Train Dataset: {train_df.shape}\")\n",
    "print(f\"Test Datasets: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The train dataset contains 3,000,888 rows and 6 columns while the test dataset contains 28,512 rows and 5 columns.\n",
    "\n",
    "The train dataset is significantly larger than the test dataset in terms of the number of rows. This is expected, as the train dataset is usually larger to provide sufficient data for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of Each Dataset:\n",
      "Holiday Events Dataset: (350, 6)\n",
      "Oil Dataset: (1218, 2)\n",
      "Stores Dataset: (54, 5)\n",
      "Transactions Dataset: (83488, 3)\n"
     ]
    }
   ],
   "source": [
    "# Print out the shapes of the other datasets\n",
    "print(\"Shapes of Each Dataset:\")\n",
    "print(f\"Holiday Events Dataset: {holidays_events_df.shape}\")\n",
    "print(f\"Oil Dataset: {oil_df.shape}\")\n",
    "print(f\"Stores Dataset: {stores_df.shape}\")\n",
    "print(f\"Transactions Dataset: {transactions_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Holiday Events dataset contains 350 rows and 6 columns. This dataset provides information about various holidays and events.\n",
    "\n",
    "The Oil dataset consists of 1,218 rows and 2 columns. This dataset includes information about the daily price of oil.\n",
    "\n",
    "The Stores dataset contains 54 rows and 5 columns. This dataset provides details about different stores, such as their locations, types, and clusters.\n",
    "\n",
    "The Transactions dataset contains 83,488 rows and 3 columns. This dataset contains information about the number of transactions made at each store on specific dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Column Information of The Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Get the column information of each dataset\n",
    "# Function to display column information of the datasets\n",
    "def show_column_info(dataset_name, dataset):\n",
    "    print(f\"Data types for the {dataset_name} dataset:\")\n",
    "    print(dataset.info())\n",
    "    print('==='*14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types for the Train dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000888 entries, 0 to 3000887\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Dtype  \n",
      "---  ------       -----  \n",
      " 0   id           int64  \n",
      " 1   date         object \n",
      " 2   store_nbr    int64  \n",
      " 3   family       object \n",
      " 4   sales        float64\n",
      " 5   onpromotion  int64  \n",
      "dtypes: float64(1), int64(3), object(2)\n",
      "memory usage: 137.4+ MB\n",
      "None\n",
      "==========================================\n",
      "\n",
      "Data types for the Test dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 28512 entries, 0 to 28511\n",
      "Data columns (total 5 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   id           28512 non-null  int64 \n",
      " 1   date         28512 non-null  object\n",
      " 2   store_nbr    28512 non-null  int64 \n",
      " 3   family       28512 non-null  object\n",
      " 4   onpromotion  28512 non-null  int64 \n",
      "dtypes: int64(3), object(2)\n",
      "memory usage: 1.1+ MB\n",
      "None\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Column information of the train and test columns\n",
    "show_column_info('Train', train_df)\n",
    "print()\n",
    "show_column_info('Test', test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The train dataset contains 3,000,888 entries and 6 columns: 'id', 'date', 'store_nbr', 'family', 'sales', and 'onpromotion'.\n",
    "- The test dataset contains 28,512 entries and 5 columns: 'id', 'date', 'store_nbr', 'family', and 'onpromotion'.\n",
    "- The \"date\" column in both datasets of type object. It needs to be converted to a datetime data type for further analysis.\n",
    "- As expected, the test dataset does not have the \"sales\" column. This column is not needed because 'sales' is the variable we want to predict. The goal is to use the trained model to predict or forecast the sales in the test data based on the other available features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data types for the Holiday events dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 350 entries, 0 to 349\n",
      "Data columns (total 6 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   date         350 non-null    object\n",
      " 1   type         350 non-null    object\n",
      " 2   locale       350 non-null    object\n",
      " 3   locale_name  350 non-null    object\n",
      " 4   description  350 non-null    object\n",
      " 5   transferred  350 non-null    bool  \n",
      "dtypes: bool(1), object(5)\n",
      "memory usage: 14.1+ KB\n",
      "None\n",
      "==========================================\n",
      "\n",
      "Data types for the Oil dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1218 entries, 0 to 1217\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   date        1218 non-null   object \n",
      " 1   dcoilwtico  1175 non-null   float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 19.2+ KB\n",
      "None\n",
      "==========================================\n",
      "\n",
      "Data types for the Stores dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 54 entries, 0 to 53\n",
      "Data columns (total 5 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   store_nbr  54 non-null     int64 \n",
      " 1   city       54 non-null     object\n",
      " 2   state      54 non-null     object\n",
      " 3   type       54 non-null     object\n",
      " 4   cluster    54 non-null     int64 \n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 2.2+ KB\n",
      "None\n",
      "==========================================\n",
      "\n",
      "Data types for the Transactions dataset:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83488 entries, 0 to 83487\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   date          83488 non-null  object\n",
      " 1   store_nbr     83488 non-null  int64 \n",
      " 2   transactions  83488 non-null  int64 \n",
      "dtypes: int64(2), object(1)\n",
      "memory usage: 1.9+ MB\n",
      "None\n",
      "==========================================\n"
     ]
    }
   ],
   "source": [
    "# Column information of the other datasets\n",
    "show_column_info('Holiday events', holidays_events_df)\n",
    "print()\n",
    "show_column_info('Oil', oil_df)\n",
    "print()\n",
    "show_column_info('Stores', stores_df)\n",
    "print()\n",
    "show_column_info('Transactions', transactions_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### The Holiday Events Dataset:\n",
    "- The dataset contains 350 entries and 6 columns: 'date', 'type', 'locale', 'locale_name', 'description', and 'transferred'.\n",
    "- The \"date\" column in the dataset is of type object. It needs to be converted to a datetime data type for further analysis.\n",
    "\n",
    "##### The Oil Dataset:\n",
    "- The dataset contains 1,218 entries has 2 columns: 'date' and 'dcoilwtico'.\n",
    "- The \"date\" column in the dataset is of type object. It needs to be converted to a datetime data type for further analysis.\n",
    "- The 'dcoilwtico' column has 1,175 non-null values, indicating that there are some missing values in this column.\n",
    "\n",
    "##### The Stores dataset:\n",
    "- The dataset contains 54 entries and 5 columns: 'store_nbr', 'city', 'state', 'type', and 'cluster'.\n",
    "\n",
    "##### The Transactions dataset:\n",
    "- The dataset contains 83,488 entries and 3 columns: 'date', 'store_nbr', and 'transactions'.\n",
    "- The \"date\" column in the dataset is of type object. It needs to be converted to a datetime data type for further analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iii. Transforming the 'date' column to datetime format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Column Data Type After Transformation:\n",
      "Train dataset: datetime64[ns]\n",
      "Test dataset: datetime64[ns]\n",
      "Holiday Events dataset: datetime64[ns]\n",
      "Oil dataset: datetime64[ns]\n",
      "Transactions dataset: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Converting the 'date' column in the datasets to datetime format\n",
    "# Train dataset\n",
    "train_df['date'] = pd.to_datetime(train_df['date'])\n",
    "\n",
    "# Test dataset\n",
    "test_df['date'] = pd.to_datetime(test_df['date'])\n",
    "\n",
    "# Holiday Events dataset\n",
    "holidays_events_df['date'] = pd.to_datetime(holidays_events_df['date'])\n",
    "\n",
    "# Oil dataset\n",
    "oil_df['date'] = pd.to_datetime(oil_df['date'])\n",
    "\n",
    "# Transactions dataset\n",
    "transactions_df['date'] = pd.to_datetime(transactions_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date Column Data Type After Transformation:\n",
      "==========================================\n",
      "Train dataset: datetime64[ns]\n",
      "Test dataset: datetime64[ns]\n",
      "Holiday Events dataset: datetime64[ns]\n",
      "Oil dataset: datetime64[ns]\n",
      "Transactions dataset: datetime64[ns]\n"
     ]
    }
   ],
   "source": [
    "# Confirm the data type of the 'date' column after transformation\n",
    "print('Date Column Data Type After Transformation:') \n",
    "print('==='*14)\n",
    "print(\"Train dataset:\", train_df['date'].dtype)\n",
    "print(\"Test dataset:\", test_df['date'].dtype)\n",
    "print(\"Holiday Events dataset:\", holidays_events_df['date'].dtype)\n",
    "print(\"Oil dataset:\", oil_df['date'].dtype)\n",
    "print(\"Transactions dataset:\", transactions_df['date'].dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Summary statistics of the datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train dataset summary statistics:\n",
      "\n",
      "                 id     store_nbr         sales   onpromotion\n",
      "count  3.000888e+06  3.000888e+06  3.000888e+06  3.000888e+06\n",
      "mean   1.500444e+06  2.750000e+01  3.577757e+02  2.602770e+00\n",
      "std    8.662819e+05  1.558579e+01  1.101998e+03  1.221888e+01\n",
      "min    0.000000e+00  1.000000e+00  0.000000e+00  0.000000e+00\n",
      "25%    7.502218e+05  1.400000e+01  0.000000e+00  0.000000e+00\n",
      "50%    1.500444e+06  2.750000e+01  1.100000e+01  0.000000e+00\n",
      "75%    2.250665e+06  4.100000e+01  1.958473e+02  0.000000e+00\n",
      "max    3.000887e+06  5.400000e+01  1.247170e+05  7.410000e+02\n",
      "============================================================\n",
      "\n",
      "Test dataset summary statistics:\n",
      "\n",
      "                 id     store_nbr   onpromotion\n",
      "count  2.851200e+04  28512.000000  28512.000000\n",
      "mean   3.015144e+06     27.500000      6.965383\n",
      "std    8.230850e+03     15.586057     20.683952\n",
      "min    3.000888e+06      1.000000      0.000000\n",
      "25%    3.008016e+06     14.000000      0.000000\n",
      "50%    3.015144e+06     27.500000      0.000000\n",
      "75%    3.022271e+06     41.000000      6.000000\n",
      "max    3.029399e+06     54.000000    646.000000\n",
      "============================================================\n",
      "\n",
      "Holiday events dataset summary statistics:\n",
      "\n",
      "                       date     type    locale locale_name description  \\\n",
      "count                   350      350       350         350         350   \n",
      "unique                  312        6         3          24         103   \n",
      "top     2014-06-25 00:00:00  Holiday  National     Ecuador    Carnaval   \n",
      "freq                      4      221       174         174          10   \n",
      "first   2012-03-02 00:00:00      NaN       NaN         NaN         NaN   \n",
      "last    2017-12-26 00:00:00      NaN       NaN         NaN         NaN   \n",
      "\n",
      "       transferred  \n",
      "count          350  \n",
      "unique           2  \n",
      "top          False  \n",
      "freq           338  \n",
      "first          NaN  \n",
      "last           NaN  \n",
      "============================================================\n",
      "\n",
      "Oil dataset summary statistics:\n",
      "\n",
      "        dcoilwtico\n",
      "count  1175.000000\n",
      "mean     67.714366\n",
      "std      25.630476\n",
      "min      26.190001\n",
      "25%      46.405001\n",
      "50%      53.189999\n",
      "75%      95.660000\n",
      "max     110.620003\n",
      "============================================================\n",
      "\n",
      "Stores dataset summary statistics:\n",
      "\n",
      "       store_nbr    cluster\n",
      "count  54.000000  54.000000\n",
      "mean   27.500000   8.481481\n",
      "std    15.732133   4.693395\n",
      "min     1.000000   1.000000\n",
      "25%    14.250000   4.000000\n",
      "50%    27.500000   8.500000\n",
      "75%    40.750000  13.000000\n",
      "max    54.000000  17.000000\n",
      "============================================================\n",
      "\n",
      "Transactions dataset summary statistics:\n",
      "\n",
      "          store_nbr  transactions\n",
      "count  83488.000000  83488.000000\n",
      "mean      26.939237   1694.602158\n",
      "std       15.608204    963.286644\n",
      "min        1.000000      5.000000\n",
      "25%       13.000000   1046.000000\n",
      "50%       27.000000   1393.000000\n",
      "75%       40.000000   2079.000000\n",
      "max       54.000000   8359.000000\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Checking for the summary statistics of the datasets\n",
    "\n",
    "datasets = {'train': train_df, 'test': test_df, 'holiday events': holidays_events_df, 'oil': oil_df, 'stores': stores_df, 'transactions': transactions_df}\n",
    "\n",
    "for name, data in datasets.items():\n",
    "    print(f\"\\n{name.capitalize()} dataset summary statistics:\\n\")\n",
    "    print(data.describe())\n",
    "    print('==='*20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in the Train dataset:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "sales          0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "======================================================\n",
      "Missing values in the Test dataset:\n",
      "id             0\n",
      "date           0\n",
      "store_nbr      0\n",
      "family         0\n",
      "onpromotion    0\n",
      "dtype: int64\n",
      "======================================================\n",
      "Missing values in the Holiday events dataset:\n",
      "date           0\n",
      "type           0\n",
      "locale         0\n",
      "locale_name    0\n",
      "description    0\n",
      "transferred    0\n",
      "dtype: int64\n",
      "======================================================\n",
      "Missing values in the Oil dataset:\n",
      "date           0\n",
      "dcoilwtico    43\n",
      "dtype: int64\n",
      "======================================================\n",
      "Missing values in the Stores dataset:\n",
      "store_nbr    0\n",
      "city         0\n",
      "state        0\n",
      "type         0\n",
      "cluster      0\n",
      "dtype: int64\n",
      "======================================================\n",
      "Missing values in the Transactions dataset:\n",
      "date            0\n",
      "store_nbr       0\n",
      "transactions    0\n",
      "dtype: int64\n",
      "======================================================\n"
     ]
    }
   ],
   "source": [
    "# Check for missing values in the datasets\n",
    "datasets = {'train': train_df, 'test': test_df, 'holiday events': holidays_events_df, 'oil': oil_df, 'stores': stores_df, 'transactions': transactions_df, }\n",
    "\n",
    "def show_missing_values(datasets):\n",
    "    for name, data in datasets.items():\n",
    "        print(f\"Missing values in the {name.capitalize()} dataset:\")\n",
    "        print(data.isnull().sum())\n",
    "        print('===' * 18)\n",
    "\n",
    "show_missing_values(datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Of all the columns in the different datasets, it is only the 'dcoilwtico' column in the Oil dataset which has missing values. The column has 43 missing values."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
